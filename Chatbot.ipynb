{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obero\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\obero\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\obero\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.txa6yqsd3gcqqc22geq54j2udcxdxhwn.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Medicine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>drool,agitation,nightmare,rhonchus,consciousne...</td>\n",
       "      <td>Alzheimer's disease</td>\n",
       "      <td>rivastigmine,donepezil,galantamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fever,night sweat,spontaneous rupture of membr...</td>\n",
       "      <td>HIV</td>\n",
       "      <td>abacavir,lamivudine,stavudine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>yellow sputum,cachexia,chill,decreased body we...</td>\n",
       "      <td>Pneumocystis carinii pneumonia</td>\n",
       "      <td>tetracyclines,macrodile antibiotic,penicillin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dysarthria,asthenia,speech slurred,facial pare...</td>\n",
       "      <td>accident cerebrovascular</td>\n",
       "      <td>statin,alteplase,apixaban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fever,night sweat,spontaneous rupture of membr...</td>\n",
       "      <td>acquired immuno-deficiency syndrome</td>\n",
       "      <td>amantadine,acyclovir,rolaids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Target  \\\n",
       "0  drool,agitation,nightmare,rhonchus,consciousne...   \n",
       "1  fever,night sweat,spontaneous rupture of membr...   \n",
       "2  yellow sputum,cachexia,chill,decreased body we...   \n",
       "3  dysarthria,asthenia,speech slurred,facial pare...   \n",
       "4  fever,night sweat,spontaneous rupture of membr...   \n",
       "\n",
       "                                Source  \\\n",
       "0                  Alzheimer's disease   \n",
       "1                                  HIV   \n",
       "2       Pneumocystis carinii pneumonia   \n",
       "3             accident cerebrovascular   \n",
       "4  acquired immuno-deficiency syndrome   \n",
       "\n",
       "                                        Medicine  \n",
       "0             rivastigmine,donepezil,galantamine  \n",
       "1                  abacavir,lamivudine,stavudine  \n",
       "2  tetracyclines,macrodile antibiotic,penicillin  \n",
       "3                      statin,alteplase,apixaban  \n",
       "4                   amantadine,acyclovir,rolaids  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "\n",
    "# Reading our data\n",
    "df = pd.read_csv('disease.csv')\n",
    "df[\"Target\"]= df[\"Target\"].str.replace(\"\\t\", \",\", case = False) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "list1 = []\n",
    "corpus = []\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "for i in range(149):\n",
    "    list1.append(remove_accented_chars(df['Target'][i]))\n",
    "df['Target'] = list1\n",
    "\n",
    "\n",
    "for i in range(0, 149):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Target'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    #ps = PorterStemmer() \n",
    "    #review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    \n",
    "    \n",
    "# Making a dictionary of disease and its symptoms\n",
    "dict1 = {}\n",
    "for i in range(149):\n",
    "    dict1[df['Source'][i]] = corpus[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chat with user\n",
    "while True:\n",
    "    symptoms = input('Tell me the symptoms or type quit to exit:')\n",
    "    symptoms = symptoms.lower()\n",
    "    if symptoms == 'quit':\n",
    "        print('Bye! Have a good day!')\n",
    "        break\n",
    "    else:\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~''' \n",
    "        for x in symptoms.lower(): \n",
    "            if x in punctuations: \n",
    "                symptoms = symptoms.replace(x, \" \") \n",
    "        symptoms = symptoms.split()\n",
    "        list1 = []\n",
    "        for i in symptoms:\n",
    "            for k,v in dict1.items():\n",
    "                if i in v:\n",
    "                    k = k.replace(u'\\xa0', u' ')\n",
    "                    list1.append([k])\n",
    "                else:\n",
    "                    pass\n",
    "        word_counts = Counter(word for words in list1 for word in words)\n",
    "        print('The disease(s) you are most likely to have on the basis of the symptoms given are:  ')\n",
    "        count = 1\n",
    "        for elements in word_counts.most_common(5):\n",
    "            print('\\n{}.'.format(count),elements[0])\n",
    "            print('\\nThe medicines/drugs for it are: ')\n",
    "            for items in df[df['Source'] == elements[0]]['Medicine']:\n",
    "                items = items.split(',')\n",
    "                for medicine in items:\n",
    "                    print(medicine.title())\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#Ignore any warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Get the article URL\n",
    "article = Article('https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "text = corpus\n",
    "sent_tokens = nltk.sent_tokenize(text) #Convert the text into a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = [\"hi\", \"hello\", \"hola\", \"greetings\", \"wassup\", \"hey\"]\n",
    "\n",
    "#Greeting responses back to the user\n",
    "GREETING_RESPONSES=[\"howdy\", \"hi\", \"hey\", \"what's good\", \"hello\", \"hey there\"]\n",
    "\n",
    "#Function to return a random greeting response to a users greeting\n",
    "def greeting(sentence):\n",
    "    #if the user's input is a greeting, then return a randomly chosen greeting response\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct_dict = dict(  ( ord(punct),None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return nltk.word_tokenize(text.lower().translate(remove_punct_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    #The users response / query\n",
    "    #user_response = 'What is chronic kidney disease'\n",
    "\n",
    "    user_response = user_response.lower() #Make the response lower case\n",
    "\n",
    "    ###Print the users query/ response\n",
    "    #print(user_response)\n",
    "\n",
    "    #Set the chatbot response to an empty string\n",
    "    robo_response = ''\n",
    "\n",
    "    #Append the users response to the sentence list\n",
    "    sent_tokens.append(user_response)\n",
    "\n",
    "    ###Print the sentence list after appending the users response\n",
    "    #print(sent_tokens)\n",
    "\n",
    "    #Create a TfidfVectorizer Object\n",
    "    TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words='english')\n",
    "\n",
    "    #Convert the text to a matrix of TF-IDF features\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "\n",
    "    ###Print the TFIDF features\n",
    "    #print(tfidf)\n",
    "\n",
    "    #Get the measure of similarity (similarity scores)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "\n",
    "    #Print the similarity scores\n",
    "    #print(vals)\n",
    "\n",
    "    #Get the index of the most similar text/sentence to the users response\n",
    "    idx = vals.argsort()[0][-2]\n",
    "\n",
    "    #Reduce the dimensionality of vals\n",
    "    flat = vals.flatten()\n",
    "\n",
    "    #sort the list in ascending order\n",
    "    flat.sort()\n",
    "\n",
    "    #Get the most similar score to the users response\n",
    "    score = flat[-2]\n",
    "\n",
    "    #Print the similarity score\n",
    "    #print(score)\n",
    "\n",
    "    #If the variable 'score' is 0 then their is no text similar to the users response\n",
    "    if(score == 0):\n",
    "        robo_response = robo_response+\"I apologize, I don't understand.\"\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "  \n",
    "    #Print the chat bot response\n",
    "    #print(robo_response)\n",
    "  \n",
    "    #Remove the users response from the sentence tokens list\n",
    "    sent_tokens.remove(user_response)\n",
    "  \n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HealthBot: I am HealthBot. If you want to exit, type Bye!\")\n",
    "flag = True\n",
    "while(flag == True):\n",
    "    user_response = input('User Input: ')\n",
    "    user_response = user_response.lower()\n",
    "    if(user_response != 'bye'):\n",
    "        if(user_response == 'thanks' or user_response =='thank you'):\n",
    "            flag=False\n",
    "            print(\"HealthBot: You are welcome !\")\n",
    "        else:\n",
    "            if(greeting(user_response) != None):\n",
    "                print(\"HealthBot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"HealthBot: \"+response(user_response))       \n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"HealthBot: Chat with you later !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
